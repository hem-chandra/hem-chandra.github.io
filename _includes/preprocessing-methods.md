## ðŸ‘‹ Hi, welcome!

This page highlights our **preprocessing-based fairness methods**, which operate on the **training data** before any machine learning (ML) model is built. These approaches aim to reduce or eliminate bias at the data source, helping ensure that downstream models make fairer and more responsible predictions.

Since ML models learn patterns directly from training data, any bias present in that data can lead to unfair or discriminatory outcomes during prediction.

 {% include_relative _includes/preprocessing-publications.md %}  
